{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from utils.plot import plot_barv, colors\n",
    "\n",
    "theor_epses = [1.0, 2.0, 4.0, 10.0]\n",
    "\n",
    "img_dir = 'exp_data/images/'\n",
    "os.makedirs(img_dir, exist_ok=True)\n",
    "\n",
    "exp_folder = 'exp_data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Average-case vs Worst-case $\\theta_0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impact of initialization\n",
    "records = []\n",
    "for data_name in ['mnist', 'cifar10']:\n",
    "    for init_type in ['fixed_average', 'fixed_worst']:\n",
    "        for epsilon in [1.0, 2.0, 4.0, 10.0]:\n",
    "            emp_epses = np.array([np.load(f'{exp_folder}/model_init/{init_type}/seed{seed}/{data_name}_half_cnn_eps{epsilon}/emp_eps_loss.npy')[0] for seed in range(5)])\n",
    "            test_accs = np.load(f'{exp_folder}/model_init/{init_type}/seed0/{data_name}_half_cnn_eps{epsilon}/test_set_accs.npy')\n",
    "\n",
    "            records.append({\n",
    "                'data_name': data_name,\n",
    "                'init_type': init_type,\n",
    "                'theor_eps': epsilon,\n",
    "                'emp_eps_mean': emp_epses.mean(),\n",
    "                'emp_eps_std': emp_epses.std(),\n",
    "                'emp_eps_max': emp_epses.max(),\n",
    "                'test_acc': test_accs.mean()\n",
    "            })\n",
    "results = pd.DataFrame.from_records(records)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impact of initialization\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "for ax, data_name in zip(axs.flat, ['mnist', 'cifar10']):\n",
    "    resultss = [results[(results['data_name'] == data_name) & (results['init_type'] == init_type)] for init_type in ['fixed_average', 'fixed_worst']]\n",
    "\n",
    "    plot_barv(ax, resultss, ['Average-case $\\\\theta_0$', 'Worst-case $\\\\theta_0$'], title=data_name.upper())\n",
    "\n",
    "fig.set_size_inches(12, 3)\n",
    "h,l = ax.get_legend_handles_labels()\n",
    "fig.legend(h, l, loc='upper center', ncol=4, bbox_to_anchor=(0.5, 1.15))\n",
    "fig.savefig(f'{img_dir}/model_init.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Impact of pre-training epochs in worst-case $\\theta_0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile results into pandas dataframe\n",
    "n_epochss = [0, 1, 2, 3, 4, 5]\n",
    "results = []\n",
    "for n_epochs in n_epochss:\n",
    "    grad_norms, emp_epses = [], []\n",
    "    for seed in range(5):\n",
    "        folder = f'{exp_folder}/pretrain_epochs/{n_epochs}epochs/seed{seed}/mnist_half_cnn_eps10.0'\n",
    "\n",
    "        grad_norm = np.load(f'{folder}/all_grad_norms_out.npy', allow_pickle=True)[0, 0]['after'].mean()\n",
    "        test_acc = np.load(f'{folder}/test_set_accs.npy').mean()\n",
    "        emp_eps = np.load(f'{folder}/emp_eps_loss.npy')\n",
    "\n",
    "        grad_norms.append(grad_norm)\n",
    "        emp_epses.append(emp_eps)\n",
    "    \n",
    "    results.append({\n",
    "        'n_epochs': n_epochs,\n",
    "        'test_acc': test_acc,\n",
    "        'grad_norm': np.mean(grad_norms),\n",
    "        'emp_eps_mean': np.mean(emp_epses),\n",
    "        'emp_eps_std': np.std(emp_epses)\n",
    "    })\n",
    "\n",
    "results = pd.DataFrame.from_records(results)\n",
    "print(results)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# grad_norm vs n_iters\n",
    "ax.plot(results['n_epochs'].to_numpy(), results['grad_norm'].to_numpy(), marker='*', color=colors[0], label='Gradient norm')\n",
    "ax.set_ylabel('Average gradient norm', color=colors[0])\n",
    "ax.set_xticks(n_epochss)\n",
    "ax.set_xlabel('Number of pre-training epochs')\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "ax2.errorbar(results['n_epochs'].to_numpy(), results['emp_eps_mean'].to_numpy(), marker='*', color=colors[1], yerr=results['emp_eps_std'].to_numpy(), capsize=3, label='$\\\\varepsilon_{emp}$')\n",
    "ax2.set_ylabel('Empirical $\\\\varepsilon_{emp}$', color=colors[1])\n",
    "ax2.set_ylim(0, 10)\n",
    "ax2.set_xticks(n_epochss)\n",
    "ax2.set_xlabel('Number of pre-training epochs')\n",
    "\n",
    "# combined legend\n",
    "lines, labels = ax.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax.legend(lines + lines2, labels + labels2, loc=0)\n",
    "\n",
    "fig.set_size_inches(5, 4)\n",
    "fig.savefig(f'{img_dir}/grad_norms.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Impact of dataset size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impact of dataset size\n",
    "records = []\n",
    "for data_name in ['mnist', 'cifar10']:\n",
    "    for n_samples in [100, 1000, -1]:\n",
    "        for epsilon in [1.0, 2.0, 4.0, 10.0]:\n",
    "            emp_epses = np.array([np.load(f'{exp_folder}/dataset_size/{n_samples}samples/seed{seed}/{data_name}_half_cnn_eps{epsilon}/emp_eps_loss.npy')[0] for seed in range(5)])\n",
    "            test_accs = np.load(f'{exp_folder}/dataset_size/{n_samples}samples/seed0/{data_name}_half_cnn_eps{epsilon}/test_set_accs.npy')\n",
    "\n",
    "            records.append({\n",
    "                'data_name': data_name,\n",
    "                'n_samples': n_samples,\n",
    "                'theor_eps': epsilon,\n",
    "                'emp_eps_mean': emp_epses.mean(),\n",
    "                'emp_eps_std': emp_epses.std(),\n",
    "                'emp_eps_max': emp_epses.max(),\n",
    "                'test_acc': test_accs.mean()\n",
    "            })\n",
    "results = pd.DataFrame.from_records(records)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impact of dataset size\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "for ax, data_name in zip(axs.flat, ['mnist', 'cifar10']):\n",
    "    resultss = [results[(results['data_name'] == data_name) & (results['n_samples'] == n_samples)] for n_samples in [100, 1000, -1]]\n",
    "\n",
    "    plot_barv(ax, resultss, ['$n = 100$', '$n = 1{,}000$', '$n = |\\\\mathcal{D}|$'], title=data_name.upper())\n",
    "\n",
    "h,l = ax.get_legend_handles_labels()\n",
    "fig.legend(h, l, loc='upper center', ncol=5, bbox_to_anchor=(0.5, 1.15))\n",
    "fig.set_size_inches(12, 3)\n",
    "fig.savefig(f'{img_dir}/dataset_size.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Impact of gradient clipping norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impact of gradient clipping norm\n",
    "records = []\n",
    "for data_name in ['mnist', 'cifar10']:\n",
    "    for max_grad_norm in [0.1, 1.0, 10.0]:\n",
    "        for epsilon in [1.0, 2.0, 4.0, 10.0]:\n",
    "            emp_epses = np.array([np.load(f'{exp_folder}/max_grad_norm/{max_grad_norm}/seed{seed}/{data_name}_half_cnn_eps{epsilon}/emp_eps_loss.npy')[0] for seed in range(5)])\n",
    "            test_set_accs = np.load(f'{exp_folder}/max_grad_norm/{max_grad_norm}/seed0/{data_name}_half_cnn_eps{epsilon}/test_set_accs.npy')\n",
    "\n",
    "            records.append({\n",
    "                'data_name': data_name,\n",
    "                'max_grad_norm': max_grad_norm,\n",
    "                'theor_eps': epsilon,\n",
    "                'emp_eps_mean': emp_epses.mean(),\n",
    "                'emp_eps_std': emp_epses.std(),\n",
    "                'emp_eps_max': emp_epses.max(),\n",
    "                'test_acc_mean': test_set_accs.mean()\n",
    "            })\n",
    "results = pd.DataFrame.from_records(records)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sensitivity to grad norm\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "for ax, data_name in zip(axs.flat, ['mnist', 'cifar10']):\n",
    "    resultss = [results[(results['data_name'] == data_name) & (results['max_grad_norm'] == max_grad_norm)] for max_grad_norm in [0.1, 1.0, 10.0]]\n",
    "\n",
    "    plot_barv(ax, resultss, ['$C = 0.1$', '$C = 1.0$', '$C = 10.0$'], title=data_name.upper())\n",
    "\n",
    "h,l = ax.get_legend_handles_labels()\n",
    "fig.legend(h, l, loc='upper center', ncol=5, bbox_to_anchor=(0.5, 1.15))\n",
    "fig.set_size_inches(12, 3)\n",
    "fig.savefig(f'{img_dir}/max_grad_norm.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning last layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Average-case vs Worst-case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impact of initialization\n",
    "records = []\n",
    "for init_type in ['fixed_average', 'fixed_worst']:\n",
    "    for epsilon in [1.0, 2.0, 4.0, 10.0]:\n",
    "        emp_epses = np.array([np.load(f'{exp_folder}/model_init_finetune/{init_type}/seed{seed}/cifar10_half_finetune_last_lr_eps{epsilon}/emp_eps_loss.npy')[0] for seed in range(5)])\n",
    "        test_accs = np.load(f'{exp_folder}/model_init_finetune/{init_type}/seed0/cifar10_half_finetune_last_lr_eps{epsilon}/test_set_accs.npy')\n",
    "\n",
    "        records.append({\n",
    "            'init_type': init_type,\n",
    "            'theor_eps': epsilon,\n",
    "            'emp_eps_mean': emp_epses.mean(),\n",
    "            'emp_eps_std': emp_epses.std(),\n",
    "            'emp_eps_max': emp_epses.max(),\n",
    "            'test_acc': test_accs.mean()\n",
    "        })\n",
    "results = pd.DataFrame.from_records(records)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impact of model initialisation\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# prepare pandas dataframe for plot\n",
    "resultss = [results[results['init_type'] == init_type] for init_type in ['fixed_average', 'fixed_worst']]\n",
    "\n",
    "plot_barv(ax, resultss, ['Average-case $\\\\theta_0$', 'Worst-case $\\\\theta_0$'])\n",
    "\n",
    "fig.set_size_inches(12, 3)\n",
    "h,l = ax.get_legend_handles_labels()\n",
    "fig.legend(h, l, loc='upper center', ncol=4, bbox_to_anchor=(0.5, 1.05))\n",
    "fig.savefig(f'{img_dir}/model_init_finetune.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Impact of dataset size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impact of dataset size\n",
    "records = []\n",
    "for n_samples in [100, 1000, -1]:\n",
    "    for epsilon in [1.0, 2.0, 4.0, 10.0]:\n",
    "        emp_epses = np.array([np.load(f'{exp_folder}/dataset_size_finetune/{n_samples}samples/seed{seed}/cifar10_half_finetune_last_lr_eps{epsilon}/emp_eps_loss.npy')[0] for seed in range(5)])\n",
    "\n",
    "        records.append({\n",
    "            'n_samples': n_samples,\n",
    "            'theor_eps': epsilon,\n",
    "            'emp_eps_mean': emp_epses.mean(),\n",
    "            'emp_eps_std': emp_epses.std(),\n",
    "            'emp_eps_max': emp_epses.max()\n",
    "        })\n",
    "results = pd.DataFrame.from_records(records)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impact of samples\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# prepare pandas dataframe for plot\n",
    "resultss = [results[results['n_samples'] == n_samples] for n_samples in [100, 1000, -1]]\n",
    "plot_barv(ax, resultss, ['$n = 100$', '$n = 1{,}000$', '$n = |\\\\mathcal{D}|$'])\n",
    "\n",
    "fig.set_size_inches(12, 3)\n",
    "h,l = ax.get_legend_handles_labels()\n",
    "fig.legend(h, l, loc='upper center', ncol=5, bbox_to_anchor=(0.5, 1.05))\n",
    "fig.savefig(f'{img_dir}/dataset_size_finetune.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Impact of gradient clipping norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impact of gradient clipping norm\n",
    "records = []\n",
    "for max_grad_norm in [0.1, 1.0, 10.0]:\n",
    "    for epsilon in [1.0, 2.0, 4.0, 10.0]:\n",
    "        emp_epses = np.array([np.load(f'{exp_folder}/max_grad_norm_finetune/{max_grad_norm}/seed{seed}/cifar10_half_finetune_last_lr_eps{epsilon}/emp_eps_loss.npy')[0] for seed in range(5)])\n",
    "\n",
    "        records.append({\n",
    "            'max_grad_norm': max_grad_norm,\n",
    "            'theor_eps': epsilon,\n",
    "            'emp_eps_mean': emp_epses.mean(),\n",
    "            'emp_eps_std': emp_epses.std(),\n",
    "            'emp_eps_max': emp_epses.max()\n",
    "        })\n",
    "results = pd.DataFrame.from_records(records)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impact of gradient clipping norm\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# prepare pandas dataframe for plot\n",
    "resultss = [results[results['max_grad_norm'] == max_grad_norm] for max_grad_norm in [0.1, 1.0, 10.0]]\n",
    "plot_barv(ax, resultss, ['$C = 0.1$', '$C = 1.0$', '$C = 10.0$'])\n",
    "\n",
    "fig.set_size_inches(12, 3)\n",
    "h,l = ax.get_legend_handles_labels()\n",
    "fig.legend(h, l, loc='upper center', ncol=5, bbox_to_anchor=(0.5, 1.05))\n",
    "fig.savefig(f'{img_dir}/max_grad_norm_finetune.pdf', bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audit_dpsgd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
